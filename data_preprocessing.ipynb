{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ellarauth/CCN-proxy-modeling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the measurement station codes (35 stations)\n",
    "# more detailed information on the stations can be found in metadata/measurement_sites_info.txt\n",
    "stations = ['ABZ', 'ALE', 'AMA', 'AMM', 'ASP', 'BEI', 'BOT', 'BSL', 'DEL', 'EGB',\n",
    "            'FKL', 'HAD', 'HEL', 'HPB', 'HRW', 'HYY', 'KCE', 'KPZ', 'MAR', 'MHD', \n",
    "            'MLP', 'MUK', 'NAN', 'NEU', 'POV', 'SAO', 'SCH', 'SGP', 'UAE', 'PRL',\n",
    "            'VAR', 'VHL', 'VIE', 'WAL', 'ZOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets(folder):\n",
    "    '''\n",
    "    Concatenates the individual datasets for all measurement stations in a specified folder located in \"data/\".\n",
    "    \n",
    "    Parameters:\n",
    "    folder (str): Name of folder located in the \"data/\" folder of the repository\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: data frame of the concatenated data sets in the folder\n",
    "    '''\n",
    "    \n",
    "    full_df = []\n",
    "\n",
    "    for s in stations:\n",
    "        df = pd.read_csv('data/'+folder+'/'+s+'.csv')\n",
    "        df['station'] = s\n",
    "        full_df.append(df)\n",
    "\n",
    "    full_df = pd.concat(full_df)\n",
    "    full_df = full_df.reset_index(drop=True)\n",
    "    full_df['id'] = [full_df.station[i] + '-' + str(full_df.date[i]) for i in range(full_df.shape[0])]\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the aerosol mixing ratio data and saving it as a separate csv file\n",
    "# a full description of all variable names can be found in metadata/variable_names.txt\n",
    "aerosols_df = combine_datasets('aerosols')\n",
    "aerosols_df = aerosols_df[['id', 'latitude', 'longitude', 'aermr01', 'aermr02', \n",
    "                           'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "                           'aermr08', 'aermr09', 'aermr10', 'aermr11']]\n",
    "aerosols_df.to_csv('data/aerosols_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the atmospheric data, calculating the relative humidity, and saving it as a separate csv file\n",
    "atmospheric_df = combine_datasets('atmospheric')\n",
    "atmospheric_df = atmospheric_df[['id', 'd2m', 't2m']]\n",
    "td = atmospheric_df.d2m - 273.15\n",
    "t = atmospheric_df.t2m - 273.15\n",
    "atmospheric_df['rh'] = 100*(np.exp((17.625*td) / (243.04+td)) / np.exp((17.625*t) / (243.04+t)))\n",
    "atmospheric_df.to_csv('data/atmospheric_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the boundary layer height data and saving it as a separate csv file\n",
    "boundary_layer_height_df = combine_datasets('boundary_layer_height')\n",
    "boundary_layer_height_df = boundary_layer_height_df[['id', 'blh']]\n",
    "boundary_layer_height_df.to_csv('data/boundary_layer_height_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the gas data and saving it as a separate csv file\n",
    "gases_df = combine_datasets('gases')\n",
    "gases_df = gases_df[['id', 'co', 'c5h8', 'no2', 'no', 'so2']]\n",
    "gases_df.to_csv('data/gases_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the slow access data and saving it as a separate csv file\n",
    "slow_access_df = combine_datasets('slow_access')\n",
    "slow_access_df = slow_access_df[['id', 'nh3', 'crwc', 'c10h16']]\n",
    "slow_access_df.to_csv('data/slow_access_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the wind data, calculating the wind speed, and saving it as a separate csv file\n",
    "wind_df = combine_datasets('wind')\n",
    "wind_df['wind_speed'] = np.sqrt(wind_df.u**2 + wind_df.v**2)\n",
    "wind_df = wind_df[['id', 'wind_speed']]\n",
    "wind_df.to_csv('data/wind.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the n100 data and saving it as a separate csv file\n",
    "n100_df = []\n",
    "for s in stations:\n",
    "    df = pd.read_table('data/N100_proxy/'+s+'_N100.dat', sep='\\s+', \n",
    "                       names=['year', 'month', 'day', 'hour', 'minute', 'n100'])\n",
    "    \n",
    "    # AMA and UAE are in UTC, so the times of the measurements need to be adjusted to local time\n",
    "    if (s == 'AMA'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date -= timedelta(hours=4)\n",
    "        df.date = [d.replace(hour=0, minute=0, second=0) for d in df.date]      \n",
    "    elif (s == 'UAE'):\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "        df.date += timedelta(hours=4)\n",
    "        df.date = [d.replace(hour=0, minute=0, second=0) for d in df.date]\n",
    "        \n",
    "    # the year for FKL is multiplied by 2 due to some bug, so needs to be corrected\n",
    "    elif (s == 'FKL'):\n",
    "        df.year /= 2\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])  \n",
    "        \n",
    "    else:\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute']])\n",
    "    \n",
    "    df.drop(columns=['year', 'month', 'day', 'hour', 'minute'], inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # create empty 3 hourly dataframe - normalize converts time to midnight\n",
    "    every_3h_index = pd.date_range(df.index.min().normalize(), df.index.max(), freq='3H')\n",
    "    every_3h_df = pd.DataFrame(index=every_3h_index, columns=['n100'])\n",
    "    \n",
    "    # concatenate original and 3 hourly df, drop duplicate timestamps keeping observed values\n",
    "    df = pd.concat([df, every_3h_df], join='outer').sort_index()\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # interpolate 3 hourly missing (NaN) values, drop edge cases\n",
    "    df = df.interpolate(method='time').dropna()\n",
    "    \n",
    "    df['date'] = df.index\n",
    "    df['station'] = s\n",
    "    n100_df.append(df)\n",
    "\n",
    "n100_df = pd.concat(n100_df)\n",
    "n100_df = n100_df[n100_df.n100 > 0]\n",
    "n100_df = n100_df.reset_index(drop=True)\n",
    "n100_df['id'] = [n100_df.station[i] + '-' + str(n100_df.date[i]) for i in range(n100_df.shape[0])]\n",
    "n100_df = n100_df[['id', 'station', 'date', 'n100']]\n",
    "n100_df.to_csv('data/n100_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>n100</th>\n",
       "      <th>aermr01</th>\n",
       "      <th>aermr02</th>\n",
       "      <th>aermr03</th>\n",
       "      <th>aermr04</th>\n",
       "      <th>...</th>\n",
       "      <th>nh3</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>d2m</th>\n",
       "      <th>t2m</th>\n",
       "      <th>crwc</th>\n",
       "      <th>blh</th>\n",
       "      <th>rh</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABZ-2012-01-26 18:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 18:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2860.264407</td>\n",
       "      <td>1.130925e-11</td>\n",
       "      <td>9.656489e-10</td>\n",
       "      <td>5.386068e-11</td>\n",
       "      <td>8.925737e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>7.087745e-10</td>\n",
       "      <td>1.416274e-09</td>\n",
       "      <td>2.257734e-08</td>\n",
       "      <td>5.335189e-09</td>\n",
       "      <td>265.94745</td>\n",
       "      <td>268.02210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.34552</td>\n",
       "      <td>85.351851</td>\n",
       "      <td>2.343428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABZ-2012-01-26 21:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-26 21:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2765.461017</td>\n",
       "      <td>1.221719e-11</td>\n",
       "      <td>1.043291e-09</td>\n",
       "      <td>4.078474e-11</td>\n",
       "      <td>1.820321e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>9.279780e-10</td>\n",
       "      <td>3.197272e-09</td>\n",
       "      <td>2.466686e-08</td>\n",
       "      <td>7.637095e-09</td>\n",
       "      <td>264.51917</td>\n",
       "      <td>266.25134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256.22314</td>\n",
       "      <td>87.455067</td>\n",
       "      <td>2.290729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABZ-2012-01-27 00:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-27 00:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2073.905085</td>\n",
       "      <td>7.723116e-12</td>\n",
       "      <td>6.594735e-10</td>\n",
       "      <td>1.707053e-11</td>\n",
       "      <td>8.950445e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.503275e-09</td>\n",
       "      <td>9.322101e-09</td>\n",
       "      <td>2.733719e-08</td>\n",
       "      <td>1.188354e-08</td>\n",
       "      <td>264.04578</td>\n",
       "      <td>265.29468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.99615</td>\n",
       "      <td>90.734149</td>\n",
       "      <td>1.933842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABZ-2012-01-27 03:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-27 03:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>1711.154237</td>\n",
       "      <td>4.699148e-12</td>\n",
       "      <td>4.011062e-10</td>\n",
       "      <td>8.261608e-12</td>\n",
       "      <td>3.943629e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589063e-09</td>\n",
       "      <td>1.865987e-08</td>\n",
       "      <td>2.964443e-08</td>\n",
       "      <td>1.186046e-08</td>\n",
       "      <td>263.76500</td>\n",
       "      <td>265.05933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.33954</td>\n",
       "      <td>90.393698</td>\n",
       "      <td>1.588926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABZ-2012-01-27 06:00:00</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>2012-01-27 06:00:00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2081.242373</td>\n",
       "      <td>3.720708e-12</td>\n",
       "      <td>3.175671e-10</td>\n",
       "      <td>4.759155e-12</td>\n",
       "      <td>1.120592e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.028960e-09</td>\n",
       "      <td>3.099397e-08</td>\n",
       "      <td>2.678388e-08</td>\n",
       "      <td>7.433328e-09</td>\n",
       "      <td>264.02032</td>\n",
       "      <td>265.33960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.06348</td>\n",
       "      <td>90.239081</td>\n",
       "      <td>1.724053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id station                date  latitude  longitude  \\\n",
       "0  ABZ-2012-01-26 18:00:00     ABZ 2012-01-26 18:00:00     50.57      12.99   \n",
       "1  ABZ-2012-01-26 21:00:00     ABZ 2012-01-26 21:00:00     50.57      12.99   \n",
       "2  ABZ-2012-01-27 00:00:00     ABZ 2012-01-27 00:00:00     50.57      12.99   \n",
       "3  ABZ-2012-01-27 03:00:00     ABZ 2012-01-27 03:00:00     50.57      12.99   \n",
       "4  ABZ-2012-01-27 06:00:00     ABZ 2012-01-27 06:00:00     50.57      12.99   \n",
       "\n",
       "          n100       aermr01       aermr02       aermr03       aermr04  ...  \\\n",
       "0  2860.264407  1.130925e-11  9.656489e-10  5.386068e-11  8.925737e-15  ...   \n",
       "1  2765.461017  1.221719e-11  1.043291e-09  4.078474e-11  1.820321e-15  ...   \n",
       "2  2073.905085  7.723116e-12  6.594735e-10  1.707053e-11  8.950445e-14  ...   \n",
       "3  1711.154237  4.699148e-12  4.011062e-10  8.261608e-12  3.943629e-13  ...   \n",
       "4  2081.242373  3.720708e-12  3.175671e-10  4.759155e-12  1.120592e-12  ...   \n",
       "\n",
       "            nh3            no           no2           so2        d2m  \\\n",
       "0  7.087745e-10  1.416274e-09  2.257734e-08  5.335189e-09  265.94745   \n",
       "1  9.279780e-10  3.197272e-09  2.466686e-08  7.637095e-09  264.51917   \n",
       "2  1.503275e-09  9.322101e-09  2.733719e-08  1.188354e-08  264.04578   \n",
       "3  1.589063e-09  1.865987e-08  2.964443e-08  1.186046e-08  263.76500   \n",
       "4  1.028960e-09  3.099397e-08  2.678388e-08  7.433328e-09  264.02032   \n",
       "\n",
       "         t2m  crwc        blh         rh  wind_speed  \n",
       "0  268.02210   0.0  341.34552  85.351851    2.343428  \n",
       "1  266.25134   0.0  256.22314  87.455067    2.290729  \n",
       "2  265.29468   0.0  172.99615  90.734149    1.933842  \n",
       "3  265.05933   0.0  147.33954  90.393698    1.588926  \n",
       "4  265.33960   0.0  112.06348  90.239081    1.724053  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining all the data sets into one dataframe\n",
    "data = n100_df.merge(aerosols_df, on='id')\n",
    "data = data.merge(atmospheric_df, on='id')\n",
    "data = data.merge(boundary_layer_height_df, on='id')\n",
    "data = data.merge(gases_df, on='id')\n",
    "data = data.merge(slow_access_df, on='id')\n",
    "data = data.merge(wind_df, on='id')\n",
    "\n",
    "# removing outliers for VHL\n",
    "for i, row in data.loc[data.station == 'VHL'].iterrows():\n",
    "    if row.n100 > 10000:\n",
    "        data.drop(index=i, inplace=True)\n",
    "\n",
    "# reordering the columns\n",
    "data = data[['id', 'station', 'date', 'latitude', 'longitude', 'n100', \n",
    "             'aermr01', 'aermr02', 'aermr03', 'aermr04', 'aermr05', 'aermr06', 'aermr07', \n",
    "             'aermr08', 'aermr09', 'aermr10', 'aermr11', 'co', 'c5h8', 'c10h16', 'nh3', \n",
    "             'no', 'no2', 'so2', 'd2m', 't2m', 'crwc', 'blh', 'rh', 'wind_speed']]\n",
    "\n",
    "# saving the full dataset\n",
    "data.date = pd.to_datetime(data.date)\n",
    "data = data.dropna(axis=0)\n",
    "data.to_csv('data/full_data.csv', index=False)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
